{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"e0e-ZRtgBZ4i"},"outputs":[],"source":["# import pkl with cleaned text- the only preprocessing done is to remove non-letter or number characters from the text and lowercase it\n","# next remove stopwords and lemmatize or stem the text\n","# then use LDA to parse topics\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u57MXaH6CPdW"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m6Efmq-zCQbP"},"outputs":[],"source":["import pandas as pd\n","import pickle\n","import os\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import gensim\n","import gensim.corpora as corpora\n","from gensim.models.coherencemodel import CoherenceModel\n","from gensim.corpora.dictionary import Dictionary\n","\n","import matplotlib.pyplot as plt\n","from gensim.models import Phrases\n","from gensim.models.phrases import Phraser\n","import numpy as np\n","#from kneed import KneeLocator # ! pip install kneed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmi76-XjCj71"},"outputs":[],"source":["# Read in the data\n","reviews = pickle.load(open('/Users/Melissa/Desktop/NLP_Fall2021/final_project/reviews_with_topics.pkl', 'rb'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uRD2abmnTJHN","outputId":"59408bdf-e55c-4b7a-9382-a0f59c36651e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/Melissa/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /Users/Melissa/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /Users/Melissa/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["# Remove stopwords + a few more- this is the same processing as for the topic modeling, just without the str_split \n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","sw = stopwords.words('english')\n","sw.extend(['many', 'good', 'like', 'liked', 'well', 'great', 'get', 'also', 'really', 'very', 'put'])\n"," \n","# Remove custom stopwords\n","def rem_sw(var):\n","    my_test = [word for word in var.split() if word not in sw]\n","    my_test = ' '.join(my_test)\n","    return my_test\n","\n","# Remove words less than 3 characters\n","def length_fun(var):\n","    tmp_txt = [word for word in var.split() if len(word) > 2]\n","    tmp_txt = ' '.join(tmp_txt)\n","    return tmp_txt\n","\n","# Stem text\n","def stem_fun(var):\n","    from nltk.stem.porter import PorterStemmer\n","    stemmer = PorterStemmer()\n","    tmp_txt = [stemmer.stem(word) for word in var.split()]\n","    tmp_txt = ' '.join(tmp_txt)\n","    return tmp_txt\n","\n","# Lemmatize the text\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","wordnet_lemmatizer = WordNetLemmatizer()\n","\n","def lemmatize_fun(var):\n","    tmp_txt = [wordnet_lemmatizer.lemmatize(word) for word in var.split()]\n","    tmp_txt = ' '.join(tmp_txt)\n","    return tmp_txt\n","\n","\n","# Text has been cleaned to only include words and numbers, had stopwords removed, words less than 3 characters removed, and lemmatized (not stemmed here)\n","reviews['review_body_clean_3'] = reviews['review_body_clean'].apply(rem_sw).apply(length_fun).apply(lemmatize_fun).apply(rem_sw) \n"]},{"cell_type":"markdown","metadata":{"id":"Pk4vltKT4Eh7"},"source":["# Embeddings for Review Classification \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srfVrIT0KCk9"},"outputs":[],"source":["#! pip install --upgrade gensim\n","#from gensim.models import Word2Vec"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0erALUCXTJHd"},"outputs":[],"source":["reviews['review_category'].value_counts()\n","\n","# Flag reviews by sentiment\n","def review_sentiment(df):\n","    if df['star_rating'] >= 4:\n","        return 'positive'\n","    elif df['star_rating'] == 3:\n","        return 'neutral'\n","    elif df['star_rating'] <= 2:\n","        return 'negative'\n","\n","reviews['review_category'] = reviews.apply(review_sentiment, axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qrgFUBZTJHg","outputId":"40a99360-662a-451e-8e58-713d2d89dc82"},"outputs":[{"data":{"text/plain":["positive    42252\n","neutral      4830\n","negative     3935\n","Name: review_category, dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["reviews['review_category'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4NzjVJZzEjdx"},"outputs":[],"source":["# Review_body_clean_3 is the input that we will create embeddings from\n","# the only difference is removing the split at the end\n","# Review_category is the dependent variable in the predictive model\n","\n","the_path = '/Users/Melissa/Desktop/NLP_Fall2021/final_project/'\n","\n","def extract_embeddings_domain(df_in, num_vec_in, path_in):\n","    from gensim.models import Word2Vec\n","    import pandas as pd\n","    import numpy as np\n","    import pickle\n","    \n","    model = Word2Vec(df_in.str.split(), min_count=1,vector_size=num_vec_in, workers=3, window=5, sg=0)\n","    \n","    wrd_dict = model.wv.key_to_index\n","    def get_score(var):\n","        try:\n","            tmp_arr = list()\n","            for word in var:\n","                tmp_arr.append(list(model.wv[word]))\n","        except:\n","            pass\n","        return np.mean(np.array(tmp_arr), axis=0)\n","    tmp_out = df_in.str.split().apply(get_score)\n","    tmp_data = tmp_out.apply(pd.Series).fillna(0)\n","    pickle.dump(model, open(path_in + 'melissa_embeddings_domain_model.pkl', 'wb'))\n","    pickle.dump(tmp_data, open(path_in + 'melissa_embeddings_df_domain.pkl', 'wb'))\n","    return tmp_data, wrd_dict, model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FjwDCRhF7OU"},"outputs":[],"source":["emb_data, word_dict, emb_domain_model =  extract_embeddings_domain(reviews.review_body_clean_3, 300, the_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mOmvvVklTJHq","outputId":"271324bd-8b58-4de2-b3fc-01134ecccd8d"},"outputs":[{"data":{"text/plain":["Index(['marketplace', 'customer_id', 'review_id', 'product_id',\n","       'product_parent', 'product_title', 'product_category', 'star_rating',\n","       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n","       'review_headline', 'review_body', 'review_date', 'review_category',\n","       'review_body_clean', 'review_body_clean_2', 'topic_1', 'topic_2',\n","       'topic_3', 'topic_4', 'topic_5', 'topic_6', 'topic_7',\n","       'review_body_clean_3'],\n","      dtype='object')"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["reviews.columns"]},{"cell_type":"markdown","metadata":{"id":"vZwhhJevTJHs"},"source":["### Append the embeddings to the reviews dataframe as additional columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3a6cAwpTTJHu"},"outputs":[],"source":["topics = reviews[['topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5', 'topic_6', 'topic_7']]\n","                  \n","categories = reviews['review_category']\n","\n","topics_embeddings = pd.concat([topics, emb_data], axis = 1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNcwBymPTJHw"},"outputs":[],"source":["# Must encode the target variable\n","\n","from sklearn import preprocessing\n","labeler = preprocessing.LabelEncoder()\n","categories_encoded = labeler.fit_transform(categories)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZrOPavU1TJHx","outputId":"9d41e1ba-be3a-40e6-8ed4-da0518655428"},"outputs":[{"data":{"text/plain":["positive    42252\n","neutral      4830\n","negative     3935\n","Name: review_category, dtype: int64"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["categories.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"en6lW0CoTJHz","outputId":"e0863c6b-9b22-45d2-8d38-83c05123c128"},"outputs":[{"data":{"text/plain":["2    42252\n","1     4830\n","0     3935\n","dtype: int64"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(categories_encoded).value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LmPFFRh2TJH0"},"outputs":[],"source":["# Dump the dataframes\n","#pickle.dump(topics_embeddings, open('/Users/Melissa/Desktop/NLP_Fall2021/final_project/topics_embeddings_df.pkl', 'wb'))\n","\n","#pickle.dump(categories, open('/Users/Melissa/Desktop/NLP_Fall2021/final_project/categories_df_CORRECTED.pkl', 'wb'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRfgLRzuTJH2"},"outputs":[],"source":["# Random Forest\n","# Model with the topics and the embeddings as predictors of review category\n","def my_model_fun_grid(df_in, label_in):\n","    from sklearn.ensemble import RandomForestClassifier\n","    from sklearn.model_selection import train_test_split\n","    import pandas as pd\n","    from sklearn.metrics import precision_recall_fscore_support\n","    from sklearn.metrics import classification_report\n","    import pickle\n","    from sklearn.model_selection import GridSearchCV\n","    my_model = RandomForestClassifier(random_state = 123)\n","    parameters = {'n_estimators':[10, 100], 'max_depth':[None, 1, 10],\n","                  'random_state': [123], 'class_weight': ['balanced']}\n","    my_grid = GridSearchCV(my_model, parameters)\n","    \n","    #80/20 train,test,split\n","    X_train, X_test, y_train, y_test = train_test_split(df_in, label_in, test_size = 0.20, random_state = 123)\n","    my_grid.fit(X_train, y_train)\n","    print (\"Best Score:\", my_grid.best_score_)\n","    best_params = my_grid.best_params_\n","    my_model_opt = RandomForestClassifier(**best_params)\n","    my_model_opt.fit(X_train, y_train)\n","    #pickle.dump(my_model_opt, open(path_o + \"my_model.pkl\", \"wb\"))\n","    y_pred = my_model_opt.predict(X_test)\n","    #model_metrics = pd.DataFrame(precision_recall_fscore_support(y_test, y_pred, average = 'weighted'))\n","    #model_metrics.index = ['precision', 'recall', 'fscore', 'none']\n","    model_metrics = classification_report(y_test, y_pred)\n","    \n","    # function 2 prediction\n","    the_preds = pd.DataFrame(my_model_opt.predict_proba(X_test))\n","    the_preds.columns = my_model_opt.classes_\n","    return my_model_opt, model_metrics, the_preds\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"akH-9CVeTJH3","outputId":"d810cd7a-d809-4617-c937-b8514b19c0e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Score: 0.8351505347594465\n"]}],"source":["model1, metrics1, preds1 = my_model_fun_grid(topics_embeddings, categories_encoded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuusA0TGTJH5","outputId":"9a1df47d-4f51-4d99-989f-84901b77a3f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.12      0.20       794\n","           1       0.41      0.02      0.03       976\n","           2       0.84      1.00      0.91      8434\n","\n","    accuracy                           0.83     10204\n","   macro avg       0.61      0.38      0.38     10204\n","weighted avg       0.78      0.83      0.77     10204\n","\n"]}],"source":["print('Random Forest')\n","print(metrics1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q8XarIKYTJH6"},"outputs":[],"source":["# KNN Classifier\n","\n","def my_model_fun_grid_2(df_in, label_in):\n","    from sklearn.neighbors import KNeighborsClassifier\n","    from sklearn.model_selection import train_test_split\n","    import pandas as pd\n","    from sklearn.metrics import precision_recall_fscore_support\n","    from sklearn.metrics import classification_report\n","    import pickle\n","    from sklearn.model_selection import GridSearchCV\n","    my_model = KNeighborsClassifier()\n","    parameters = {'n_neighbors':[5, 50, 100]}\n","    my_grid = GridSearchCV(my_model, parameters)\n","    \n","    #80/20 train,test,split\n","    X_train, X_test, y_train, y_test = train_test_split(df_in, label_in, test_size = 0.20, random_state = 123)\n","    my_grid.fit(X_train, y_train)\n","    print (\"Best Score:\", my_grid.best_score_)\n","    best_params = my_grid.best_params_\n","    my_model_opt = KNeighborsClassifier(**best_params)\n","    my_model_opt.fit(X_train, y_train)\n","    y_pred = my_model_opt.predict(X_test)\n","    model_metrics = classification_report(y_test, y_pred)\n","    \n","    # function 2 prediction\n","    the_preds = pd.DataFrame(my_model_opt.predict_proba(X_test))\n","    the_preds.columns = my_model_opt.classes_\n","    return my_model_opt, model_metrics, the_preds\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"07SSuKMsTJH8","outputId":"a767f12e-5109-4a08-bdcb-3a3ebd5fe23c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Score: 0.8357631297116642\n"]}],"source":["model2, metrics2, preds2 = my_model_fun_grid_2(topics_embeddings, categories_encoded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1PyPsaf1TJH-","outputId":"a63d5e65-0d2b-4ad4-b03d-8098cec23865"},"outputs":[{"name":"stdout","output_type":"stream","text":["K-Nearest Neighbors Classifier\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.13      0.21       794\n","           1       0.39      0.03      0.05       976\n","           2       0.84      0.99      0.91      8434\n","\n","    accuracy                           0.83     10204\n","   macro avg       0.60      0.38      0.39     10204\n","weighted avg       0.78      0.83      0.78     10204\n","\n"]}],"source":["print('K-Nearest Neighbors Classifier')\n","print(metrics2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PmDWsxFLTJH_","outputId":"27371c57-8513-479e-ee94-f185b2964f52"},"outputs":[{"data":{"text/plain":["KNeighborsClassifier(n_neighbors=50)"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["model2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TcBJMmAyTJIB"},"outputs":[],"source":[""]}],"metadata":{"colab":{"name":"Melissa_NLP Final Project 12.12.21 Embeddings Classifications.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}